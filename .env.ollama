# Ollama (Fully Local)
# Use this for 100% offline/local embeddings

EMBEDDING_PROVIDER=ollama
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_MODEL=nomic-embed-text

# Prerequisites:
# 1. docker-compose --profile ollama up -d
# 2. docker exec aeo-geo-ollama ollama pull nomic-embed-text

# Run with:
# cp .env.ollama .env
# ./mvnw spring-boot:run -Dspring-boot.run.profiles=ollama
